# ========================================
# PROMETHEUS RAG - Environment Configuration
# ========================================
# Copy this file to .env and configure for your environment

# ========================================
# SECURITY (REQUIRED)
# ========================================
# CRITICAL: Change this in production! Generate with: openssl rand -hex 32
SECRET_KEY=change-this-to-a-secure-random-string-in-production
SESSION_EXPIRY_DAYS=30

# ========================================
# DATABASE
# ========================================
DATABASE_PATH=prometheus.db
CHROMA_PATH=chroma_db

# ========================================
# DATASET
# ========================================
# Path to your funding dataset CSV file
DATASET_PATH=../dataset/cleaned_funding_synthetic_2010_2025.csv

# ========================================
# OLLAMA LLM
# ========================================
# Ollama server URL (use service name in Docker: http://ollama:11434)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# ========================================
# REDIS (Optional - for caching)
# ========================================
REDIS_ENABLED=false
REDIS_HOST=localhost
REDIS_PORT=6379

# ========================================
# CORS (Frontend Origins)
# ========================================
# Comma-separated list of allowed origins
# Production: https://yourdomain.com,https://www.yourdomain.com
# Development: http://localhost:3000,http://localhost:5173
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# ========================================
# SERVER
# ========================================
HOST=0.0.0.0
PORT=8000
# Set to false in production!
DEBUG=false
LOG_LEVEL=INFO

# ========================================
# RATE LIMITING
# ========================================
RATE_LIMIT_ENABLED=true
LOGIN_RATE_LIMIT=5/minute
API_RATE_LIMIT=100/minute

# ========================================
# WHISPER STT (Speech-to-Text)
# ========================================
# Model sizes: tiny, base, small, medium, large-v3
# Larger = better accuracy but slower
WHISPER_MODEL_SIZE=base
# Device: cpu, cuda (GPU)
WHISPER_DEVICE=cpu
# Compute: int8 (faster), float16, float32
WHISPER_COMPUTE_TYPE=int8

# ========================================
# PRODUCTION DEPLOYMENT NOTES
# ========================================
# 1. Generate strong SECRET_KEY: openssl rand -hex 32
# 2. Set DEBUG=false
# 3. Update ALLOWED_ORIGINS with your production domain
# 4. Use HTTPS in production (configure reverse proxy/load balancer)
# 5. Set appropriate LOG_LEVEL (WARNING or ERROR in production)
# 6. Consider enabling REDIS for production caching
# 7. Mount volumes for DATABASE_PATH and CHROMA_PATH in Docker
# 8. Backup database regularly
# 9. Monitor rate limits and adjust as needed
# 10. Keep Ollama model updated
