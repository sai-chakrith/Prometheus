# Environment Setup for RAGAS Evaluation

This file contains sample environment variables needed for RAGAS evaluation.
Copy this file to `.env` and fill in your actual values.

## Required Variables

# OpenAI API Key (required for RAGAS evaluation)
OPENAI_API_KEY=your-openai-api-key-here

## Optional Variables

# Model Configuration
RAGAS_LLM_MODEL=gpt-3.5-turbo
RAGAS_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Evaluation Settings
RAGAS_ENABLE_EXPORT=true
RAGAS_EXPORT_PATH=./evaluation_results

# RAG System Configuration
VECTOR_INDEX_PATH=data/vector_index.pkl
DATA_PATH=data/cleaned_funding.csv

## How to Use

### Windows PowerShell
```powershell
$env:OPENAI_API_KEY="your-key-here"
```

### Linux/Mac Bash
```bash
export OPENAI_API_KEY="your-key-here"
```

### Using .env file
1. Install python-dotenv: `pip install python-dotenv`
2. Copy this file to `.env`
3. Load in your Python code:
   ```python
   from dotenv import load_dotenv
   load_dotenv()
   ```

## Getting an OpenAI API Key

1. Go to https://platform.openai.com/
2. Sign up or log in
3. Navigate to API Keys section
4. Create a new API key
5. Copy and paste it here

## Cost Considerations

RAGAS evaluation uses the OpenAI API which incurs costs:
- GPT-3.5-turbo: ~$0.001 per query (recommended for testing)
- GPT-4: ~$0.03 per query (better quality, higher cost)

Estimated costs for full evaluation:
- Quick test (3 questions): ~$0.01 - $0.05
- Full test (12 questions): ~$0.05 - $0.20

## Alternative: Use Free/Local Models

For cost-free evaluation, you can modify the evaluator to use:
1. Open-source models via Hugging Face
2. Local LLMs (Ollama, LLaMA, etc.)
3. Limited metrics that don't require LLM

Note: Some RAGAS metrics require an LLM and cannot run without one.
